A complete Q-Learning implementation for the OpenAI Gym Taxi-v3 environment, along with a fully interactive Streamlit dashboard for visualizing how the trained taxi agent behaves, earns rewards, and optimizes routes.

This project is great for learning reinforcement learning and understanding how Q-learning works on a discrete action/state environment.

ğŸ¯ Features
ğŸ§  Q-Learning Training (taxi_with_dataset.py)

Trains the Taxi-v3 agent for 16,000 episodes

Automatically saves:

Q-table

Training transitions dataset

Episode rewards

Training reward curve

Greedy policy dataset

Renders evaluation episodes after training

ğŸ“Š Interactive Dashboard (taxi_dashboard.py)

Live 5Ã—5 grid environment

Taxi position, passenger, destination indicators

Step-by-step or autoplay mode

Rewards, penalties, step cost, base fare, net profit

Full episode transition log

Training curve viewer

Greedy policy dataset viewer

ğŸ“ Project Structure
Taxi-v3-Q-Learning/
â”‚
â”œâ”€â”€ taxi_dashboard.py                # Streamlit dashboard
â”œâ”€â”€ taxi_with_dataset.py             # Q-learning training script
â”œâ”€â”€ requirements.txt                 # Dependencies
â”œâ”€â”€ LICENSE                          # MIT License
â””â”€â”€ README.md                        # Documentation


Auto-generated after training:

taxi_output/
â”‚â”€â”€ taxi_q_table.npy
â”‚â”€â”€ taxi_episode_rewards.csv
â”‚â”€â”€ taxi_transitions_train.csv
â”‚â”€â”€ taxi_policy_demo.csv
â””â”€â”€ training_curve.png

âš™ï¸ Installation
git clone https://github.com/Avijal/Taxi-v3-Q-Learning.git
cd Taxi-v3-Q-Learning
pip install -r requirements.txt

ğŸ‹ï¸ Train the Q-Learning Agent

Run the training script:

python taxi_with_dataset.py


This will create the taxi_output/ folder containing:

Q-table

Training datasets

Training curve (PNG)

Greedy policy dataset

ğŸ® Launch the Dashboard

After training:

streamlit run taxi_dashboard.py


The dashboard will load the trained Q-table and display a live simulation of the taxi agent.

ğŸ§  Advanced Explanation
ğŸ”¹ State Representation

Each of the 500 states is encoded as:

(taxi_row, taxi_col, passenger_location, destination)


5 rows

5 columns

5 passenger positions (4 landmarks + inside taxi)

4 destinations

ğŸ”¹ Action Space
ID	Action
0	South
1	North
2	East
3	West
4	Pickup
5	Dropoff
ğŸ”¹ Reward System
Action	Reward
Successful dropoff	+20
Illegal pickup/dropoff	-10
Every step	-1
ğŸ”¹ Q-Learning Update Rule
Q(s,a) â† Q(s,a) + Î± [ r + Î³ max(Q(s'),:) â€“ Q(s,a) ]


Training uses:

Î± = 0.1

Î³ = 0.99

Îµ-greedy exploration (1.0 â†’ 0.05)

ğŸ“ License

This project is licensed under the MIT License.

â­ Support

If this project helped you, consider giving the repository a star on GitHub!
